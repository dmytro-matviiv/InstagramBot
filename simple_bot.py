#!/usr/bin/env python3
"""
–°–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è Instagram –±–æ—Ç–∞ –±–µ–∑ –ø–æ—à—É–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω—å
–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –∑–∞–≥–ª—É—à–∫—É –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∞–±–æ –±–µ—Ä–µ—Ç—å—Å—è –∑ –Ω–æ–≤–∏–Ω–∏
"""

import os
import time
import random
import logging
from datetime import datetime
from news_collector import NewsCollector
from content_generator import ContentGenerator
from instagram_publisher import InstagramPublisher
from translator import NewsTranslator
from PIL import Image
import requests
from io import BytesIO

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è –±–µ–∑ –µ–º–æ–¥–∑—ñ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('instagram_bot.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

class SimpleInstagramBot:
    def __init__(self):
        self.news_collector = NewsCollector()
        self.content_generator = ContentGenerator()
        self.instagram_publisher = InstagramPublisher()
        self.translator = NewsTranslator()
        self.posted_articles = set()
    

    

    


    

    
    def extract_images_from_html(self, html_content):
        """–í–∏—Ç—è–≥—É—î URL –∑–æ–±—Ä–∞–∂–µ–Ω—å –∑ HTML –∫–æ–Ω—Ç–µ–Ω—Ç—É"""
        import re
        img_urls = []
        
        # –®—É–∫–∞—î–º–æ img —Ç–µ–≥–∏
        img_pattern = r'<img[^>]+src=["\']([^"\']+)["\'][^>]*>'
        matches = re.findall(img_pattern, html_content, re.IGNORECASE)
        
        for url in matches:
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –æ—á–µ–≤–∏–¥–Ω–æ –Ω–µ–ø—Ä–∏–¥–∞—Ç–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            if any(skip in url.lower() for skip in ['icon', 'logo', 'avatar', 'button', '1x1', 'pixel']):
                continue
            # –î–æ–¥–∞—î–º–æ —è–∫—â–æ —Ü–µ —Å—Ö–æ–∂–µ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            if any(ext in url.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                img_urls.append(url)
        
        return img_urls
    
    def try_get_larger_image_url(self, url):
        """–ù–∞–º–∞–≥–∞—î—Ç—å—Å—è –∑–Ω–∞–π—Ç–∏ –±—ñ–ª—å—à—É –≤–µ—Ä—Å—ñ—é –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è"""
        if not url:
            return url
            
        # –®–∞–±–ª–æ–Ω–∏ –¥–ª—è –∑–∞–º—ñ–Ω–∏ –º—ñ–Ω—ñ–∞—Ç—é—Ä –Ω–∞ –ø–æ–≤–Ω–æ—Ä–æ–∑–º—ñ—Ä–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        replacements = [
            # –ó–∞–≥–∞–ª—å–Ω—ñ —à–∞–±–ª–æ–Ω–∏
            ('thumb_', 'full_'),
            ('small_', 'large_'),
            ('mini_', 'full_'),
            ('/thumbs/', '/images/'),
            ('/small/', '/large/'),
            ('_150.', '_1200.'),
            ('_200.', '_1200.'),
            ('_300.', '_1200.'),
            ('_400.', '_1200.'),
            ('_500.', '_1200.'),
            ('_thumb.', '_full.'),
            ('_small.', '_large.'),
            # –†–æ–∑–º—ñ—Ä–∏ –≤ URL
            ('150x', '1200x'),
            ('200x', '1200x'),
            ('300x', '1200x'),
            ('400x', '1200x'),
            ('630x360', '1200x800'),
            ('320x240', '1280x960'),
        ]
        
        original_url = url
        for old_pattern, new_pattern in replacements:
            if old_pattern in url.lower():
                new_url = url.replace(old_pattern, new_pattern)
                if new_url != url:
                    logging.info(f"–ó–Ω–∞–π–¥–µ–Ω–æ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω–æ –±—ñ–ª—å—à–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {old_pattern} -> {new_pattern}")
                    return new_url
        
        return original_url
    
    def detect_news_category(self, title, content):
        """–í–∏–∑–Ω–∞—á–∞—î –∫–∞—Ç–µ–≥–æ—Ä—ñ—é –Ω–æ–≤–∏–Ω–∏ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç—É"""
        text = f"{title} {content}".lower()
        
        # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è –≤—ñ–π—Å—å–∫–æ–≤–∏—Ö –Ω–æ–≤–∏–Ω
        war_keywords = [
            '–≤—ñ–π–Ω–∞', 'war', '—Ñ—Ä–æ–Ω—Ç', 'front', '–±–æ–π–æ–≤—ñ', 'combat', '–Ω–∞—Å—Ç—É–ø', 'offensive',
            '–æ–±–æ—Ä–æ–Ω–∞', 'defense', '–æ–±—Å—Ç—Ä—ñ–ª', 'shelling', '—Ä–∞–∫–µ—Ç', 'missile', '–¥—Ä–æ–Ω', 'drone',
            '–≤—ñ–π—Å—å–∫–æ–≤', 'military', '–∞—Ä–º—ñ—è', 'army', '–≤—Ç—Ä–∞—Ç–∏', 'casualties', '–∑–∞–≥–∏–±–ª—ñ',
            '–ø–æ—Ä–∞–Ω–µ–Ω—ñ', 'wounded', '—Ç–∞–Ω–∫', 'tank', '–∞—Ä—Ç–∏–ª–µ—Ä—ñ—è', 'artillery',
            '–∞–≤—ñ–∞—É–¥–∞—Ä', 'airstrike', '–æ–∫—É–ø–∞—Ü', 'occupation', '–∑–≤—ñ–ª—å–Ω–µ–Ω', 'liberation'
        ]
        
        # –ü–æ–ª—ñ—Ç–∏—á–Ω—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞
        politics_keywords = [
            '–ø–æ–ª—ñ—Ç–∏–∫–∞', 'politics', '—É—Ä—è–¥', 'government', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', 'president',
            '–ø–∞—Ä–ª–∞–º–µ–Ω—Ç', 'parliament', '–º—ñ–Ω—ñ—Å—Ç—Ä', 'minister', '–∑–∞–∫–æ–Ω', 'law',
            '—Ä—ñ—à–µ–Ω–Ω—è', 'decision', '—Å–∞–Ω–∫—Ü—ñ—ó', 'sanctions'
        ]
        
        # –ú—ñ–∂–Ω–∞—Ä–æ–¥–Ω—ñ –Ω–æ–≤–∏–Ω–∏
        world_keywords = [
            '–Ω–∞—Ç–æ', 'nato', '—î–≤—Ä–æ—Å–æ—é–∑', 'eu', '—Å—à–∞', 'usa', '—Ä–æ—Å—ñ—è', 'russia',
            '–º—ñ–∂–Ω–∞—Ä–æ–¥–Ω', 'international', '–¥–∏–ø–ª–æ–º–∞—Ç', 'diplomatic'
        ]
        
        if any(keyword in text for keyword in war_keywords):
            return 'war'
        elif any(keyword in text for keyword in politics_keywords):
            return 'politics'
        elif any(keyword in text for keyword in world_keywords):
            return 'world'
        else:
            return 'news'
    
    def find_highest_quality_news(self):
        """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å –Ω–æ–≤–∏–Ω—É –∑ –Ω–∞–π–≤–∏—â–æ—é —è–∫—ñ—Å—Ç—é —Ñ–æ—Ç–æ —Å–µ—Ä–µ–¥ –í–°–Ü–• RSS –¥–∂–µ—Ä–µ–ª"""
        logging.info("üîç –ê–Ω–∞–ª—ñ–∑ –í–°–Ü–• RSS –¥–∂–µ—Ä–µ–ª –¥–ª—è –ø–æ—à—É–∫—É –Ω–∞–π—è–∫—ñ—Å–Ω—ñ—à–∏—Ö —Ñ–æ—Ç–æ...")
        
        all_news = self.news_collector.collect_fresh_news()
        if not all_news:
            logging.error("‚ùå RSS –¥–∂–µ—Ä–µ–ª–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ñ")
            return None
            
        best_news = None
        best_quality = 0
        analyzed_count = 0
        
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –Ω–æ–≤–∏–Ω–∏ –∑ —É—Å—ñ—Ö –¥–∂–µ—Ä–µ–ª
        for article in all_news:
            analyzed_count += 1
            
            # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –≤–∂–µ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω—ñ
            article_id = hash(article.get('title', '') + article.get('link', ''))
            if article_id in self.posted_articles:
                continue
                
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —è–∫—ñ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title = article.get('title', '')
            if not title or len(title) < 10 or title == '–ù–æ–≤–∏–Ω–∞ –∑ RSS':
                continue
                
            logging.info(f"üìä –ê–Ω–∞–ª—ñ–∑—É—é #{analyzed_count}: {title[:50]}...")
            
            # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ —è–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –≤ —Ü—ñ–π –Ω–æ–≤–∏–Ω—ñ
            image_info = self.analyze_image_quality_in_article(article)
            
            if image_info and image_info['total_pixels'] > best_quality:
                best_quality = image_info['total_pixels']
                best_news = {
                    'article': article,
                    'image_info': image_info
                }
                logging.info(f"üèÜ –ù–û–í–ò–ô –õ–Ü–î–ï–†: {image_info['width']}x{image_info['height']} ({image_info['total_pixels']} –ø—ñ–∫—Å–µ–ª—ñ–≤)")
            
            # –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–µ—Ä–µ–≤—ñ—Ä–æ–∫ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ
            if analyzed_count >= 30:
                break
                
        if best_news:
            logging.info(f"‚úÖ –í–ò–ë–†–ê–ù–û –ù–ê–ô–ö–†–ê–©–£: {best_news['image_info']['width']}x{best_news['image_info']['height']} ({best_news['image_info']['total_pixels']} –ø—ñ–∫—Å–µ–ª—ñ–≤)")
            return best_news
        else:
            logging.warning("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤–∏–Ω –∑ —è–∫—ñ—Å–Ω–∏–º–∏ —Ñ–æ—Ç–æ")
            return None

    def create_and_publish_post(self, max_attempts=50):
        """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—è –ø–æ—Å—Ç–∞ –∑ –Ω–∞–π–≤–∏—â–æ—é —è–∫—ñ—Å—Ç—é —Ñ–æ—Ç–æ"""
        try:
            logging.info("üéØ –ü–æ—á–∞—Ç–æ–∫ –ø–æ—à—É–∫—É –Ω–∞–π—è–∫—ñ—Å–Ω—ñ—à–∏—Ö —Ñ–æ—Ç–æ —Å–µ—Ä–µ–¥ –í–°–Ü–• RSS –¥–∂–µ—Ä–µ–ª...")
            
            if max_attempts <= 0:
                logging.error("‚ùå –î–æ—Å—è–≥–Ω—É—Ç–æ –º–∞–∫—Å–∏–º—É–º —Å–ø—Ä–æ–±")
                return False
            
            # 1. –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–æ–≤–∏–Ω—É –∑ –Ω–∞–π–≤–∏—â–æ—é —è–∫—ñ—Å—Ç—é —Ñ–æ—Ç–æ —Å–µ—Ä–µ–¥ –í–°–Ü–• –¥–∂–µ—Ä–µ–ª
            best_news = self.find_highest_quality_news()
            if not best_news:
                logging.error("‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–æ–≤–∏–Ω –∑ —è–∫—ñ—Å–Ω–∏–º–∏ —Ñ–æ—Ç–æ –≤ –∂–æ–¥–Ω–æ–º—É –¥–∂–µ—Ä–µ–ª—ñ")
                return False
                
            # –í–∏—Ç—è–≥—É—î–º–æ –¥–∞–Ω—ñ
            news_article = best_news['article']
            image_info = best_news['image_info']
            
            logging.info(f"‚úÖ –û–±—Ä–∞–Ω–æ –Ω–∞–π–∫—Ä–∞—â—É –Ω–æ–≤–∏–Ω—É: {news_article.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')}")
            logging.info(f"üì∏ –Ø–∫—ñ—Å—Ç—å —Ñ–æ—Ç–æ: {image_info['width']}x{image_info['height']} ({image_info['total_pixels']} –ø—ñ–∫—Å–µ–ª—ñ–≤)")
            
            # –î–æ–¥–∞—î–º–æ –¥–æ —Å–ø–∏—Å–∫—É –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–∏—Ö
            article_id = hash(news_article.get('title', '') + news_article.get('link', ''))
            self.posted_articles.add(article_id)
            
            # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ –Ω–æ–≤–∏–Ω—É –Ω–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É
            logging.info("–ü–µ—Ä–µ–∫–ª–∞–¥ –Ω–æ–≤–∏–Ω–∏ –Ω–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É...")
            ukrainian_article = self.translator.translate_news_article(news_article)
            logging.info(f"–ü–µ—Ä–µ–∫–ª–∞–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {ukrainian_article.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')}")
            
            # 2. –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –Ω–∞–π–∫—Ä–∞—â–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            logging.info(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –Ω–∞–π—è–∫—ñ—Å–Ω—ñ—à–µ —Ñ–æ—Ç–æ –∑ {image_info['url']}")
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                    'Accept-Language': 'uk-UA,uk;q=0.9,en;q=0.8',
                    'Referer': news_article.get('link', ''),
                    'Connection': 'keep-alive'
                }
                
                response = requests.get(image_info['url'], timeout=15, headers=headers)
                if response.status_code == 200:
                    image = Image.open(BytesIO(response.content))
                    logging.info(f"‚úÖ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –Ω–∞–π—è–∫—ñ—Å–Ω—ñ—à–µ —Ñ–æ—Ç–æ: {image.size[0]}x{image.size[1]}")
                else:
                    logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–æ—Ç–æ: {response.status_code}")
                    return self.create_and_publish_post(max_attempts - 1)
                    
            except Exception as e:
                logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Ñ–æ—Ç–æ: {e}")
                return self.create_and_publish_post(max_attempts - 1)
            
            # 3. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ë–ï–ó –æ–±—Ä–æ–±–∫–∏
            logging.info("‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ —Ñ–æ—Ç–æ –±–µ–∑ –æ–±—Ä–æ–±–∫–∏")
            processed_img = image
                
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            image_filename = f"post_{timestamp}.jpg"
            image_path = f"temp_images/{image_filename}"
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–∞–ø–∫—É —è–∫—â–æ —ó—ó –Ω–µ–º–∞—î
            os.makedirs("temp_images", exist_ok=True)
            
            processed_img.save(image_path, "JPEG", quality=95)
            logging.info(f"‚úÖ –†–ï–ê–õ–¨–ù–ï —Ñ–æ—Ç–æ –∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {image_path}")
            
            # 3. –ì–µ–Ω–µ—Ä—É—î–º–æ –∫–æ–Ω—Ç–µ–Ω—Ç –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó —Å—Ç–∞—Ç—Ç—ñ
            logging.info("–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –∫–æ–Ω—Ç–µ–Ω—Ç—É...")
            post_content = self.content_generator.create_full_post(
                ukrainian_article.get('title', ''),
                ukrainian_article.get('text', ukrainian_article.get('summary', ''))
            )
            
            logging.info(f"–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –ø–æ—Å—Ç ({len(post_content)} —Å–∏–º–≤–æ–ª—ñ–≤)")
            
            # 4. –ü—É–±–ª—ñ–∫—É—î–º–æ
            logging.info("–ü—É–±–ª—ñ–∫–∞—Ü—ñ—è –≤ Instagram...")
            success, message = self.instagram_publisher.safe_publish(
                image_path, 
                post_content,
                add_hashtags_as_comment=True
            )
            
            if success:
                logging.info(f"–ü–æ—Å—Ç —É—Å–ø—ñ—à–Ω–æ –æ–ø—É–±–ª—ñ–∫–æ–≤–∞–Ω–æ! {message}")
                self.posted_articles.add(article_id)
                return True
            else:
                logging.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó: {message}")
                return False
            
        except Exception as e:
            logging.error(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
            return False
    
    def test_run(self):
        """–¢–µ—Å—Ç –≤—Å—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤"""
        logging.info("–¢–µ—Å—Ç–æ–≤–∏–π —Ä–µ–∂–∏–º...")
        
        # –¢–µ—Å—Ç –Ω–æ–≤–∏–Ω –∑ fallback –º–µ—Ö–∞–Ω—ñ–∑–º–æ–º
        logging.info("–¢–µ—Å—Ç –∑–±–æ—Ä—É –Ω–æ–≤–∏–Ω...")
        news = self.news_collector.get_random_news()
        if news:
            logging.info(f"–ù–æ–≤–∏–Ω–∏ –ø—Ä–∞—Ü—é—é—Ç—å: {news.get('title', 'N/A')[:50]}...")
        else:
            logging.warning("–ù–µ –≤–¥–∞–ª–æ—Å—è –∑—ñ–±—Ä–∞—Ç–∏ –Ω–æ–≤–∏–Ω–∏ –∑ RSS, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ...")
            # –ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ —Ä–æ–±–æ—Ç—É –∑ —Ç–µ—Å—Ç–æ–≤–∏–º–∏ –¥–∞–Ω–∏–º–∏
            logging.info("–ù–æ–≤–∏–Ω–∏ –ø—Ä–∞—Ü—é—é—Ç—å: –¢–µ—Å—Ç–æ–≤–∞ –Ω–æ–≤–∏–Ω–∞ (fallback —Ä–µ–∂–∏–º)...")
        
        # –¢–µ—Å—Ç –¢–Ü–õ–¨–ö–ò —Ä–µ–∞–ª—å–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å
        logging.info("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Ç–µ—Å—Ç —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è - –±–æ—Ç –ø—Ä–∞—Ü—é—î –¢–Ü–õ–¨–ö–ò –∑ —Ä–µ–∞–ª—å–Ω–∏–º–∏ —Ñ–æ—Ç–æ –∑ —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç—É")
        logging.info("‚úÖ –¢–µ—Å—Ç –∑–æ–±—Ä–∞–∂–µ–Ω—å –ø—Ä–æ–ø—É—â–µ–Ω–æ - —Å–∏—Å—Ç–µ–º–∞ –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ñ —Ñ–æ—Ç–æ")
        
        # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–æ–Ω—Ç–µ–Ω—Ç—É
        logging.info("–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–æ–Ω—Ç–µ–Ω—Ç—É...")
        content = self.content_generator.create_full_post(
            "–¢–µ—Å—Ç–æ–≤–∞ –Ω–æ–≤–∏–Ω–∞", "–¶–µ —Ç–µ—Å—Ç–æ–≤–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç"
        )
        logging.info(f"–ö–æ–Ω—Ç–µ–Ω—Ç –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ: {len(content)} —Å–∏–º–≤–æ–ª—ñ–≤")
        
        # –¢–µ—Å—Ç Instagram (–ë–ï–ó —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–ª—è –±–µ–∑–ø–µ–∫–∏)
        logging.info("‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Ç–µ—Å—Ç Instagram –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è –±–ª–æ–∫—É–≤–∞–Ω—å")
        logging.info("‚úÖ Instagram —Ç–µ—Å—Ç –ø—Ä–æ–ø—É—â–µ–Ω–æ –¥–ª—è –±–µ–∑–ø–µ–∫–∏")
        
        logging.info("–í—Å—ñ —Ç–µ—Å—Ç–∏ –ø—Ä–æ–π–¥–µ–Ω–æ!")
        return True
    
    def analyze_rss_quality(self):
        """–ù–û–í–ò–ô: –ê–Ω–∞–ª—ñ–∑—É—î —è–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å —É –≤—Å—ñ—Ö RSS –¥–∂–µ—Ä–µ–ª–∞—Ö"""
        logging.info("üîç –ü–û–ß–ê–¢–û–ö –ê–ù–ê–õ–Ü–ó–£ RSS –î–ñ–ï–†–ï–õ...")
        logging.info("=" * 80)
        
        good_sources = []
        bad_sources = []
        
        for i, source in enumerate(self.news_collector.sources):
            logging.info(f"\nüì∞ –ê–Ω–∞–ª—ñ–∑—É—é –¥–∂–µ—Ä–µ–ª–æ {i+1}/{len(self.news_collector.sources)}: {source}")
            logging.info("-" * 60)
            
            try:
                articles = self.news_collector.fetch_rss_news(source)
                suitable_articles = 0
                total_articles = len(articles)
                
                if not articles:
                    logging.info("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –Ω–æ–≤–∏–Ω–∏ –∑ —Ü—å–æ–≥–æ –¥–∂–µ—Ä–µ–ª–∞")
                    bad_sources.append((source, "–ù–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π"))
                    continue
                
                for j, article in enumerate(articles[:10]):  # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –ø–µ—Ä—à—ñ 10 –Ω–æ–≤–∏–Ω
                    title = article.get('title', '–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞')[:50]
                    logging.info(f"\n  üìÑ –ù–æ–≤–∏–Ω–∞ {j+1}: {title}...")
                    
                    # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                    image = self.get_image_from_news(article, test_mode=True)
                    if image:
                        suitable_articles += 1
                        logging.info(f"  ‚úÖ –ü—ñ–¥—Ö–æ–¥—è—â—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑–Ω–∞–π–¥–µ–Ω–æ!")
                    else:
                        logging.info(f"  ‚ùå –ù–µ–º–∞—î –ø—ñ–¥—Ö–æ–¥—è—â–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å")
                
                # –û—Ü—ñ–Ω—é—î–º–æ —è–∫—ñ—Å—Ç—å –¥–∂–µ—Ä–µ–ª–∞
                success_rate = (suitable_articles / total_articles) * 100 if total_articles > 0 else 0
                
                if success_rate >= 5:  # –ú—ñ–Ω—ñ–º—É–º 5% –Ω–æ–≤–∏–Ω –∑ —è–∫—ñ—Å–Ω–∏–º–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏ (—Ä–µ–∞–ª—ñ—Å—Ç–∏—á–Ω–æ)
                    logging.info(f"\n  ‚úÖ –î–ñ–ï–†–ï–õ–û –ü–Ü–î–•–û–î–ò–¢–¨: {suitable_articles}/{total_articles} –Ω–æ–≤–∏–Ω –∑ —è–∫—ñ—Å–Ω–∏–º–∏ —Ñ–æ—Ç–æ ({success_rate:.1f}%)")
                    good_sources.append((source, success_rate))
                else:
                    logging.info(f"\n  ‚ùå –î–ñ–ï–†–ï–õ–û –ù–ï –ü–Ü–î–•–û–î–ò–¢–¨: {suitable_articles}/{total_articles} –Ω–æ–≤–∏–Ω –∑ —è–∫—ñ—Å–Ω–∏–º–∏ —Ñ–æ—Ç–æ ({success_rate:.1f}%)")
                    bad_sources.append((source, f"{success_rate:.1f}% —è–∫—ñ—Å–Ω–∏—Ö —Ñ–æ—Ç–æ"))
                    
            except Exception as e:
                logging.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É {source}: {e}")
                bad_sources.append((source, f"–ü–æ–º–∏–ª–∫–∞: {e}"))
        
        # –ü—ñ–¥—Å—É–º–æ–∫ –∞–Ω–∞–ª—ñ–∑—É
        logging.info("\n" + "=" * 80)
        logging.info("üìä –ü–Ü–î–°–£–ú–û–ö –ê–ù–ê–õ–Ü–ó–£ RSS –î–ñ–ï–†–ï–õ")
        logging.info("=" * 80)
        
        logging.info(f"\n‚úÖ –•–û–†–û–®–Ü –î–ñ–ï–†–ï–õ–ê ({len(good_sources)}):")
        for source, rate in good_sources:
            logging.info(f"  ‚Ä¢ {source} ({rate:.1f}% —è–∫—ñ—Å–Ω–∏—Ö —Ñ–æ—Ç–æ)")
        
        logging.info(f"\n‚ùå –ü–û–ì–ê–ù–Ü –î–ñ–ï–†–ï–õ–ê ({len(bad_sources)}):")
        for source, reason in bad_sources:
            logging.info(f"  ‚Ä¢ {source} - {reason}")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
        if len(good_sources) < 5:
            logging.info(f"\n‚ö†Ô∏è –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–Ø: –ü–æ—Ç—Ä—ñ–±–Ω–æ –±—ñ–ª—å—à–µ —è–∫—ñ—Å–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª (–∑–∞—Ä–∞–∑ {len(good_sources)})")
            self.suggest_new_rss_sources()
        else:
            logging.info(f"\nüéâ –í–Ü–î–ú–Ü–ù–ù–û: –ó–Ω–∞–π–¥–µ–Ω–æ {len(good_sources)} —è–∫—ñ—Å–Ω–∏—Ö –¥–∂–µ—Ä–µ–ª!")
        
        return good_sources, bad_sources
    
    def suggest_new_rss_sources(self):
        """–ü—Ä–æ–ø–æ–Ω—É—î –Ω–æ–≤—ñ RSS –¥–∂–µ—Ä–µ–ª–∞ –∑ —è–∫—ñ—Å–Ω–∏–º–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏"""
        logging.info("\nüí° –ü–†–û–ü–û–ù–û–í–ê–ù–Ü –ù–û–í–Ü RSS –î–ñ–ï–†–ï–õ–ê:")
        
        new_sources = [
            'https://www.dw.com/uk/rss/news',  # Deutsche Welle —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é
            'https://www.ukrinform.ua/rss/block-war',  # –£–∫—Ä—ñ–Ω—Ñ–æ—Ä–º –≤—ñ–π—Å—å–∫–æ–≤—ñ –Ω–æ–≤–∏–Ω–∏
            'https://espreso.tv/rss',  # –ï—Å–ø—Ä–µ—Å–æ –¢–í
            'https://www.eurointegration.com.ua/rss/',  # –Ñ–≤—Ä–æ–ø–µ–π—Å—å–∫–∞ –ø—Ä–∞–≤–¥–∞
            'https://interfax.com.ua/news/rss/',  # –Ü–Ω—Ç–µ—Ä—Ñ–∞–∫—Å –£–∫—Ä–∞—ó–Ω–∞
            'https://censor.net/includes/news_rss.php',  # –¶–µ–Ω–∑–æ—Ä.–Ω–µ—Ç
            'https://www.obozrevatel.com/rss.xml',  # –û–±–æ–∑—Ä–µ–≤–∞—Ç–µ–ª—å
            'https://gordonua.com/xml/rss_category/1.html',  # –ì–æ—Ä–¥–æ–Ω
        ]
        
        for source in new_sources:
            logging.info(f"  ‚Ä¢ {source}")
        
        logging.info("\nüîß –î–æ–¥–∞–π—Ç–µ —Ü—ñ –¥–∂–µ—Ä–µ–ª–∞ –¥–æ config.py –¥–ª—è –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ!")
    
    def get_image_from_news(self, news_article):
        """–û—Ç—Ä–∏–º—É—î —Ä–µ–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –Ω–æ–≤–∏–Ω–∏"""
        return self._analyze_images_only(news_article)
    
    def _analyze_images_only(self, news_article):
        """–¢—ñ–ª—å–∫–∏ –∞–Ω–∞–ª—ñ–∑—É—î —Ä–µ–∞–ª—å–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –±–µ–∑ fallback"""
        # –°–ø–æ—á–∞—Ç–∫—É –ø—Ä–æ–±—É—î–º–æ –≤–∑—è—Ç–∏ —Ä–µ–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –Ω–æ–≤–∏–Ω–∏
        image_urls = []
        
        # –î–æ–¥–∞—î–º–æ –±—ñ–ª—å—à–µ –¥–∂–µ—Ä–µ–ª –∑–æ–±—Ä–∞–∂–µ–Ω—å
        if news_article.get('rss_image'):
            image_urls.append(news_article['rss_image'])
        if news_article.get('top_image'):
            image_urls.append(news_article['top_image'])
        if news_article.get('images'):
            image_urls.extend(news_article['images'][:5])
            
        # –î–æ–¥–∞—î–º–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ –æ–ø–∏—Å—É
        description = news_article.get('description', '') or news_article.get('summary', '')
        if description:
            img_urls_from_desc = self.extract_images_from_html(description)
            image_urls.extend(img_urls_from_desc)
        
        # –ü—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        enhanced_urls = []
        for url in image_urls:
            enhanced_url = self.try_get_larger_image_url(url)
            if enhanced_url != url:
                enhanced_urls.append(enhanced_url)
        image_urls.extend(enhanced_urls)
            
        # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏
        image_urls = list(set([url for url in image_urls if url and url.strip()]))
        
        if not image_urls:
            return None
            
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∫–æ–∂–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        for i, image_url in enumerate(image_urls):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                    'Accept-Language': 'uk-UA,uk;q=0.9,en;q=0.8',
                    'Referer': news_article.get('link', ''),
                    'Connection': 'keep-alive'
                }
                response = requests.get(image_url, timeout=10, headers=headers, stream=True)
                
                if response.status_code == 200:
                    content_length = response.headers.get('content-length')
                    if content_length and int(content_length) < 5000:
                        continue
                        
                    img = Image.open(BytesIO(response.content))
                    width, height = img.size
                    
                    # –†–ï–ê–õ–Ü–°–¢–ò–ß–ù–ê –ü–ï–†–ï–í–Ü–†–ö–ê - –ø—Ä–∏–π–º–∞—î–º–æ –í–°–Ü —è–∫—ñ—Å–Ω—ñ —Ñ–æ—Ç–æ
                    if width < 400 or height < 300:  # –ë–∞–∑–æ–≤—ñ –º—ñ–Ω—ñ–º—É–º–∏
                        continue
                        
                    total_pixels = width * height
                    if total_pixels < 120000:  # 120K –ø—ñ–∫—Å–µ–ª—ñ–≤ –º—ñ–Ω—ñ–º—É–º (400x300)
                        continue
                    
                    # –ü–†–ò–ô–ú–ê–Ñ–ú–û –í–°–Ü –û–†–Ü–Ñ–ù–¢–ê–¶–Ü–á - –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ñ, –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ñ, –∫–≤–∞–¥—Ä–∞—Ç–Ω—ñ
                    logging.info(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ —è–∫—ñ—Å–Ω–µ —Ñ–æ—Ç–æ: {width}x{height} ({total_pixels} –ø—ñ–∫—Å–µ–ª—ñ–≤)")
                    
                    # –Ø–∫—â–æ –¥—ñ–π—à–ª–∏ —Å—é–¥–∏ - –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –ø—ñ–¥—Ö–æ–¥–∏—Ç—å!
                    return img
                    
            except Exception:
                continue
        
        return None  # –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ø—ñ–¥—Ö–æ–¥—è—â–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å
    
    def analyze_image_quality_in_article(self, news_article):
        """–ê–Ω–∞–ª—ñ–∑—É—î —è–∫—ñ—Å—Ç—å –∑–æ–±—Ä–∞–∂–µ–Ω—å –≤ —Å—Ç–∞—Ç—Ç—ñ —ñ –ø–æ–≤–µ—Ä—Ç–∞—î –Ω–∞–π–∫—Ä–∞—â—É —Ä–æ–∑–¥—ñ–ª—å–Ω—É –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å"""
        best_resolution = 0
        best_image_info = None
        
        # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ –ø–æ—Ç–µ–Ω—Ü—ñ–π–Ω—ñ URL –∑–æ–±—Ä–∞–∂–µ–Ω—å
        image_urls = []
        if news_article.get('rss_image'):
            image_urls.append(news_article['rss_image'])
        if news_article.get('top_image'):
            image_urls.append(news_article['top_image'])
        if news_article.get('images'):
            image_urls.extend(news_article['images'][:5])
            
        description = news_article.get('description', '') or news_article.get('summary', '')
        if description:
            img_urls_from_desc = self.extract_images_from_html(description)
            image_urls.extend(img_urls_from_desc)
            
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑–±—ñ–ª—å—à–µ–Ω—ñ –≤–µ—Ä—Å—ñ—ó URL
        enhanced_urls = []
        for url in image_urls:
            enhanced_url = self.try_get_larger_image_url(url)
            if enhanced_url != url:
                enhanced_urls.append(enhanced_url)
        image_urls.extend(enhanced_urls)
        
        # –í–∏–¥–∞–ª—è—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏
        image_urls = list(set([url for url in image_urls if url and url.strip()]))
        
        if not image_urls:
            return None
            
        # –ê–Ω–∞–ª—ñ–∑—É—î–º–æ –∫–æ–∂–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
        for image_url in image_urls:
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Accept': 'image/webp,image/apng,image/*,*/*;q=0.8',
                    'Accept-Language': 'uk-UA,uk;q=0.9,en;q=0.8',
                    'Referer': news_article.get('link', ''),
                    'Connection': 'keep-alive'
                }
                
                response = requests.get(image_url, timeout=10, headers=headers, stream=True)
                if response.status_code == 200:
                    content_length = response.headers.get('content-length')
                    if content_length and int(content_length) < 5000:
                        continue
                        
                    img = Image.open(BytesIO(response.content))
                    width, height = img.size
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –º—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –≤–∏–º–æ–≥–∏
                    if width < 400 or height < 300:
                        continue
                        
                    total_pixels = width * height
                    if total_pixels < 120000:
                        continue
                    
                    # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –∑ –ø–æ—Ç–æ—á–Ω–∏–º –∫—Ä–∞—â–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
                    if total_pixels > best_resolution:
                        best_resolution = total_pixels
                        best_image_info = {
                            'width': width,
                            'height': height,
                            'total_pixels': total_pixels,
                            'url': image_url,
                            'article': news_article
                        }
                        
            except Exception:
                continue
                
        return best_image_info
    



def main():
    """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    import sys
    
    bot = SimpleInstagramBot()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--test":
            bot.test_run()
        elif sys.argv[1] == "--post":
            bot.create_and_publish_post()

        else:
            print("–î–æ—Å—Ç—É–ø–Ω—ñ –æ–ø—Ü—ñ—ó:")
            print("  --test     : –¢–µ—Å—Ç–æ–≤–∏–π –∑–∞–ø—É—Å–∫")
            print("  --post     : –û–¥–Ω–æ—Ä–∞–∑–æ–≤–∞ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—è")
    else:
        # –ó–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º —Ç–µ—Å—Ç
        bot.test_run()

if __name__ == "__main__":
    main()
